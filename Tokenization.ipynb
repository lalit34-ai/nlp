{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tokenization.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "####04-02-2022"
      ],
      "metadata": {
        "id": "0ZTtuNyogqMh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "   **Tokenization**    \n",
        "The process of breaking the given text i.e. the character sequence into smaller units called tokens. "
      ],
      "metadata": {
        "id": "eJtYPkN8hQQJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "nltk package:\n"
      ],
      "metadata": {
        "id": "nLhVQnxkgwOB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cn4dDgSbgmYF"
      },
      "outputs": [],
      "source": [
        "#pip install nltk\n",
        "#conda install -c anaconda nltk\n",
        "import nltk\n",
        "#nltk.download()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Character tokenizer"
      ],
      "metadata": {
        "id": "2rvweE1AhYIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'hello world'\n",
        "lst = [x for x in text]\n",
        "print(lst)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtvpKVrkhXJz",
        "outputId": "e127f952-d569-4eb6-c176-1a543e49e24c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['h', 'e', 'l', 'l', 'o', ' ', 'w', 'o', 'r', 'l', 'd']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word tokenizer"
      ],
      "metadata": {
        "id": "z6q2TYlXhupB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tq_jA42IigZE",
        "outputId": "be94b537-bd3f-455f-db5f-f58827439679"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "text = \"Hello there! Welcome to NLP.\"\n",
        "print(word_tokenize(text))\n",
        "#Special characters will be considered as separate words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cR38UeOzhwjt",
        "outputId": "7549fcd6-c4a8-4fba-e111-400e7f6f4393"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', 'there', '!', 'Welcome', 'to', 'NLP', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"This is U.S.A!\"\n",
        "print(word_tokenize(text))\n",
        "#Even though there is fullstop in between USA, it is considered as a single word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSSePuvejT9s",
        "outputId": "c1739abc-631c-4c1b-a185-3ab4a8253afc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This', 'is', 'U.S.A', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"You're looking good!\"\n",
        "print(word_tokenize(text))\n",
        "#You and 're are considered separately"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6X6vlJNjY0C",
        "outputId": "18c43796-6805-4073-c443-26582b63f83b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['You', \"'re\", 'looking', 'good', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentence tokenizer"
      ],
      "metadata": {
        "id": "1iTH8F1bjwg4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Break the paragraph into sentences\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "text=\"It's easy to learn NLP. Hard to learn AI\"\n",
        "print(sent_tokenize(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R15-4COgjvva",
        "outputId": "26fe4843-9528-4436-b541-de9c17ae06e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"It's easy to learn NLP.\", 'Hard to learn AI']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"It's easy to learn NLP. I study NLP in U.S.A\"\n",
        "print(sent_tokenize(text))\n",
        "#U.S.A is taken as a single word inside a sentence. \n",
        "#Even though full stop is present, it is not considered as a new sentence from then."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ei5Dz71nkSj2",
        "outputId": "81f3cc3f-c241-4b4d-cba4-90d835fc3789"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"It's easy to learn NLP.\", 'I study NLP in U.S.A']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"With the help of nltk.tokenize.word_tokenize() method, we are able to extract the tokens from string of characters by using tokenize.word_tokenize() method. It actually returns the syllables from a single word. A single word can contain one or two syllables.\"\n",
        "print(sent_tokenize(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpO-bjqyklnB",
        "outputId": "4b7ab399-7e11-4801-f55b-1674c5fdab0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['With the help of nltk.tokenize.word_tokenize() method, we are able to extract the tokens from string of characters by using tokenize.word_tokenize() method.', 'It actually returns the syllables from a single word.', 'A single word can contain one or two syllables.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Whitespace tokenizer"
      ],
      "metadata": {
        "id": "lX9_O5BAlDjD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import WhitespaceTokenizer\n",
        "\n",
        "#Either with space, tab or new line, it splits the input into tokens\n",
        "text=\"Hello word\\nWelcome to Amrita\\tThankYou\"\n",
        "tokenizer=WhitespaceTokenizer()\n",
        "print(tokenizer.tokenize(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pX3aNHSulG-o",
        "outputId": "a6617881-0c58-4a20-ead2-5fd3e09f9b2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', 'word', 'Welcome', 'to', 'Amrita', 'ThankYou']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word-punct tokenizer"
      ],
      "metadata": {
        "id": "aPWAIINPl-Pp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import WordPunctTokenizer\n",
        "text = \"We're moving to U.S.A\"\n",
        "tokenizer = WordPunctTokenizer()\n",
        "print(tokenizer.tokenize(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAVCbsVjl9iq",
        "outputId": "d1e76f2b-ade6-4f26-8531-bb2fa2d86caa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['We', \"'\", 're', 'moving', 'to', 'U', '.', 'S', '.', 'A']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given a string, write a RE to delete all special characters"
      ],
      "metadata": {
        "id": "s3YHL9dHmd3s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "text = \"hello-hai-dhanya, how are you\"\n",
        "print(re.search('[^0-9a-zA-Z]',text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roNgTAoymlXJ",
        "outputId": "a62c58b0-d757-4649-cd62-dcc5e6949854"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<re.Match object; span=(5, 6), match='-'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RegexpTokenizer"
      ],
      "metadata": {
        "id": "Jv_Kr3ZToT3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "text = \"hello-hai-dhanya, how are you\"\n",
        "tokenizer=RegexpTokenizer(r\"\\w+\")\n",
        "lst=tokenizer.tokenize(text)\n",
        "lst"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9_9wu_1nhGx",
        "outputId": "dc08efe9-536c-4e14-89dd-e691eab2889a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hello', 'hai', 'dhanya', 'how', 'are', 'you']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "df = pd.DataFrame({'Phrases': ['The greatest glory in living lies not in never falling, but in rising every time we fall.',\n",
        "'The way to get started is to quit talking and begin doing.',\n",
        "'If life were predictable it would cease to be life, and be without flavor.',\n",
        "\"If you set your goals ridiculously high and it's a failure, you will fail above everyone else's success.\"]})\n",
        "df['tokenized'] = df.apply(lambda row: nltk.word_tokenize(row['Phrases']), axis=1)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "dISHVBXHoWTJ",
        "outputId": "8c1709fa-ce58-44b7-b5c2-ecd484e06766"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-33a6bc16-c5b1-48c5-b561-10fe3e9d7140\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Phrases</th>\n",
              "      <th>tokenized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The greatest glory in living lies not in never...</td>\n",
              "      <td>[The, greatest, glory, in, living, lies, not, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The way to get started is to quit talking and ...</td>\n",
              "      <td>[The, way, to, get, started, is, to, quit, tal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>If life were predictable it would cease to be ...</td>\n",
              "      <td>[If, life, were, predictable, it, would, cease...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>If you set your goals ridiculously high and it...</td>\n",
              "      <td>[If, you, set, your, goals, ridiculously, high...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-33a6bc16-c5b1-48c5-b561-10fe3e9d7140')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-33a6bc16-c5b1-48c5-b561-10fe3e9d7140 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-33a6bc16-c5b1-48c5-b561-10fe3e9d7140');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                             Phrases                                          tokenized\n",
              "0  The greatest glory in living lies not in never...  [The, greatest, glory, in, living, lies, not, ...\n",
              "1  The way to get started is to quit talking and ...  [The, way, to, get, started, is, to, quit, tal...\n",
              "2  If life were predictable it would cease to be ...  [If, life, were, predictable, it, would, cease...\n",
              "3  If you set your goals ridiculously high and it...  [If, you, set, your, goals, ridiculously, high..."
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"This is the first line of text.\\nThis is the second line of text.\"\n",
        "print(text)\n",
        "print(text.split('\\n')) #Spliting the text by '\\n'.\n",
        "print(text.split('\\t')) #Spliting the text by '\\t'.\n",
        "print(text.split('s')) #Spliting by charecter 's'.\n",
        "print(text.split()) #Spliting the text by space.\n",
        "print(word_tokenize(text)) #Tokenizing by using word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQkDQYO8o6NX",
        "outputId": "66bde646-e755-4e9f-a7a9-160629d42f2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the first line of text.\n",
            "This is the second line of text.\n",
            "['This is the first line of text.', 'This is the second line of text.']\n",
            "['This is the first line of text.\\nThis is the second line of text.']\n",
            "['Thi', ' i', ' the fir', 't line of text.\\nThi', ' i', ' the ', 'econd line of text.']\n",
            "['This', 'is', 'the', 'first', 'line', 'of', 'text.', 'This', 'is', 'the', 'second', 'line', 'of', 'text.']\n",
            "['This', 'is', 'the', 'first', 'line', 'of', 'text', '.', 'This', 'is', 'the', 'second', 'line', 'of', 'text', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Line Tokenizer"
      ],
      "metadata": {
        "id": "o4tVz38fpIna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import LineTokenizer\n",
        "\n",
        "text=\"It's easy to learn NLP. Hard to learn AI\"\n",
        "tokenizer = LineTokenizer()\n",
        "print(tokenizer.tokenize(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5QHAVwbpKi4",
        "outputId": "9016b8a5-44a2-4328-96d3-01c8eee9928a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"It's easy to learn NLP. Hard to learn AI\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"It's easy to learn NLP\\nI study NLP in U.S.A\"\n",
        "tokenizer = LineTokenizer()\n",
        "print(tokenizer.tokenize(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtZ6jkUEpiyC",
        "outputId": "03dbb12b-3791-4fbf-bd31-a3789d1c2806"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"It's easy to learn NLP\", 'I study NLP in U.S.A']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tweet tokenizer"
      ],
      "metadata": {
        "id": "soNFguRQpvnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "tokenizer = TweetTokenizer()\n",
        "print(\"Tweet tokenizer output: \", tokenizer.tokenize(\"This is a cooll #dummysmile !Hey ...Hello....\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxiv5O7Fpk6P",
        "outputId": "4018ca08-8b23-4ecd-ce27-c87aaab57fcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tweet tokenizer output:  ['This', 'is', 'a', 'cooll', '#dummysmile', '!', 'Hey', '...', 'Hello', '...']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Space tokenizer"
      ],
      "metadata": {
        "id": "htZ8eEI-qfFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import SpaceTokenizer\n",
        "\n",
        "tokenizer = SpaceTokenizer()\n",
        "print(\"Tweet tokenizer output: \", tokenizer.tokenize(\"hello world how are\\nyou\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F71vvyl_qguC",
        "outputId": "f1fd50ae-1c5e-455b-ec64-c140a49c04fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tweet tokenizer output:  ['hello', 'world', 'how', 'are\\nyou']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import SpaceTokenizer\n",
        "\n",
        "tokenizer = SpaceTokenizer()\n",
        "print(\"Tweet tokenizer output: \", tokenizer.tokenize(\"It's easy to learn NLP\\nI study NLP in U.S.A\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XottS3Pbq-RA",
        "outputId": "074b42f3-1cb7-4414-b5a0-2e87e409445d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tweet tokenizer output:  [\"It's\", 'easy', 'to', 'learn', 'NLP\\nI', 'study', 'NLP', 'in', 'U.S.A']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 08-02-2022"
      ],
      "metadata": {
        "id": "SeScQSV2tIK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "wk65_fu6tLhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"You only live once, but if you do it right, once is enough.\")\n",
        "for token in doc:\n",
        "  print(token.text)\n",
        "# dots are separated and are considered as a single token"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAG9v8LqvEy5",
        "outputId": "a4758c75-b034-46ea-b38e-1b18936d76b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You\n",
            "only\n",
            "live\n",
            "once\n",
            ",\n",
            "but\n",
            "if\n",
            "you\n",
            "do\n",
            "it\n",
            "right\n",
            ",\n",
            "once\n",
            "is\n",
            "enough\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"Don't\")\n",
        "for token in doc:\n",
        "  print(token.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcpWcVPYvwQC",
        "outputId": "5e7fad88-a8ac-4a9f-cad3-2e0000dca365"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Do\n",
            "n't\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.tokenizer import Tokenizer\n",
        "from spacy.lang.en import English\n",
        "nlp = English()\n",
        "\n",
        "#Creating a blank Tokenizer with just the English vocab\n",
        "tokenizer = Tokenizer(nlp.vocab)\n",
        "tokens = tokenizer(\"Let's go to N.Y.\")\n",
        "print(\"Blank tokenizer\", end=\":\")\n",
        "\n",
        "for token in tokens:\n",
        "  print(token, end=',')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7l4fiNqwYTw",
        "outputId": "14c1c97b-8c59-42d5-b846-9746ba3218b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Blank tokenizer:Let's,go,to,N.Y.,"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.lang.en import English\n",
        "nlp = English()\n",
        "\n",
        "# Creating a Tokenizer with the default settings for English\n",
        "tokenizer = nlp.tokenizer\n",
        "tokens = tokenizer(\"Let's go to N.Y.\")\n",
        "print(\"\\nDefault tokenizer\",end=' : ')\n",
        "\n",
        "for token in tokens:\n",
        "    print(token,end=', ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y26lZrmfxHsJ",
        "outputId": "b6bbd9b7-12d5-43b0-fd0f-b78efac9c6b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Default tokenizer : Let, 's, go, to, N.Y., "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# special case\n",
        "\n",
        "from spacy.symbols import ORTH\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"ViratKohli is the world's best batsman\")#phrase to tokenize\n",
        "print(\"Normal tokenization: \",end=' ')\n",
        "for token in doc:\n",
        "  print(token, end=', ')\n",
        "\n",
        "special_case = [{ORTH: \"Virat\"},{ORTH: \"Kohli\"}]#Adding special case rule\n",
        "nlp.tokenizer.add_special_case(\"ViratKohli\", special_case)\n",
        "doc = nlp(\"ViratKohli is the worlds best batsman\")\n",
        "\n",
        "print(\"\\nSpecial case tokenization : \", end='')\n",
        "for token in doc:\n",
        "  print(token, end=', ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "262EU7rFyVI_",
        "outputId": "03a6bd10-7ff2-429a-d85d-ae522de7bbec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normal tokenization:  ViratKohli, is, the, world, 's, best, batsman, \n",
            "Special case tokenization : Virat, Kohli, is, the, worlds, best, batsman, "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#gimme --> give me\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"Please gimme your phone\")#phrase to tokenize\n",
        "print(\"Normal tokenization: \",end=' ')\n",
        "for token in doc:\n",
        "  print(token, end=', ')\n",
        "\n",
        "special_case = [{ORTH: \"give\"},{ORTH: \"me\"}]#Adding special case rule\n",
        "nlp.tokenizer.add_special_case(\"gimme\", special_case)\n",
        "doc = nlp(\"Please gimme your phone\")\n",
        "\n",
        "print(\"\\nSpecial case tokenization : \", end='')\n",
        "for token in doc:\n",
        "  print(token, end=', ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhXvdzqpz1Wp",
        "outputId": "50f568c3-6372-4965-ce6b-af18d3223124"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normal tokenization:  Please, gimme, your, phone, \n",
            "Special case tokenization : Please, give, me, your, phone, "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Debugging the Tokenizer\n",
        "\n",
        "nlp = English()\n",
        "text = \"Let's move to L.A.\"\n",
        "doc = nlp(text)\n",
        "tok_exp = nlp.tokenizer.explain(text)\n",
        "\n",
        "for t in tok_exp:\n",
        "  print(t[1], \"\\t\", t[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KacvBEX0lyI",
        "outputId": "accfb4f6-04e9-42ff-e5df-c80147215817"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let \t SPECIAL-1\n",
            "'s \t SPECIAL-2\n",
            "move \t TOKEN\n",
            "to \t TOKEN\n",
            "L.A. \t TOKEN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####08-02-2022 - Lab session"
      ],
      "metadata": {
        "id": "PdSJLRJIgA9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "Ovi8yS3U1rHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "string = '\"I\\'m with you for ur like in U.K.'"
      ],
      "metadata": {
        "id": "SR4sJHsDgNKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(string)\n",
        "for token in doc:\n",
        "  print(token.text, end='|')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAu1HY_TgcB6",
        "outputId": "8908f0d7-54ac-47ae-f062-660733785b9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"|I|'m|with|you|for|ur|like|in|U.K.|"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc2 = nlp(u\"we're here to help! send mail to dhanya@gmail.com or visit www.amrita.edu\")\n",
        "for t in doc2:\n",
        "  print(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fKFIkz5gq4X",
        "outputId": "0480bbbc-6f16-41f2-a406-7f0768f324e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "we\n",
            "'re\n",
            "here\n",
            "to\n",
            "help\n",
            "!\n",
            "send\n",
            "mail\n",
            "to\n",
            "dhanya@gmail.com\n",
            "or\n",
            "visit\n",
            "www.amrita.edu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc3 = nlp(u'A 5km ola cab ride costs $10.00')\n",
        "for t in doc3:\n",
        "  print(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Db929ID7hQBa",
        "outputId": "53167fca-c0d3-430c-d271-9db1422f5e50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A\n",
            "5\n",
            "km\n",
            "ola\n",
            "cab\n",
            "ride\n",
            "costs\n",
            "$\n",
            "10.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(doc3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiatIAOlhdEp",
        "outputId": "7410a6b7-fefd-4e04-9274-cfb9e0b63b4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc5=nlp(u\"It's better now\")\n",
        "print(doc5[3])\n",
        "print(doc5[-2:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLHVWk4xhyyJ",
        "outputId": "fc3e41e6-a380-40f9-8259-03b57b1358e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "now\n",
            "better now\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc6 = nlp(u\"my dinner was horrible\")\n",
        "doc7 = nlp(u\"my dinner was good\")\n",
        "#do6[6]=doc[7]  assignments are not possible"
      ],
      "metadata": {
        "id": "Yha5JTwPiLJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc8 = nlp(u\"Apple to build a Hong Kong factory for $6 million\")\n",
        "for t in doc8:\n",
        "  print(t.text, end='|')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMXqRC9BieWp",
        "outputId": "a1e0e54e-3dff-482e-a7cd-41edcd549acd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple|to|build|a|Hong|Kong|factory|for|$|6|million|"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for ent in doc8.ents:\n",
        "  print(ent.text+ '-' + ent.label_+ '-' + str(spacy.explain(ent.label_)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XzAd5XjizXL",
        "outputId": "062f65f2-10a7-420a-baf7-5adc3bd065d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple-ORG-Companies, agencies, institutions, etc.\n",
            "Hong Kong-GPE-Countries, cities, states\n",
            "$6 million-MONEY-Monetary values, including unit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc9 = nlp(u\"An apple a day keeps the doctor away.\")\n",
        "for ent in doc9.ents:\n",
        "  print(ent.text+ '-' + ent.label_+ '-' + str(spacy.explain(ent.label_)))\n",
        "#no output as no entities mentioned are stored"
      ],
      "metadata": {
        "id": "vdEKu1G7jp5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chunking"
      ],
      "metadata": {
        "id": "6XcRleY7kcGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc10 = nlp(u\"autonomous cars shift insurance liability towards manufactures\")\n",
        "for chunk in doc10.noun_chunks:\n",
        "  print(chunk.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnuKRbK_kddW",
        "outputId": "4db781a8-8e56-40e7-99ab-ea8c03466adc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "autonomous cars\n",
            "insurance liability\n",
            "manufactures\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from  spacy import displacy\n",
        "displacy.render(doc8, style='dep',jupyter=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "OXgvJ3V8lbfb",
        "outputId": "9e3ba17e-7b28-4e25-ed2e-8d4b1f10a482"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"759d231456b24832ad245bef11f236b7-0\" class=\"displacy\" width=\"1975\" height=\"574.5\" direction=\"ltr\" style=\"max-width: none; height: 574.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Apple</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">to</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">PART</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">build</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">a</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">Hong</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">Kong</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">factory</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">for</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">$</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">SYM</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">6</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">NUM</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">million</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">NUM</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-759d231456b24832ad245bef11f236b7-0-0\" stroke-width=\"2px\" d=\"M245,439.5 C245,352.0 380.0,352.0 380.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-759d231456b24832ad245bef11f236b7-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M245,441.5 L237,429.5 253,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-759d231456b24832ad245bef11f236b7-0-1\" stroke-width=\"2px\" d=\"M70,439.5 C70,264.5 385.0,264.5 385.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-759d231456b24832ad245bef11f236b7-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">relcl</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M385.0,441.5 L393.0,429.5 377.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-759d231456b24832ad245bef11f236b7-0-2\" stroke-width=\"2px\" d=\"M595,439.5 C595,177.0 1090.0,177.0 1090.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-759d231456b24832ad245bef11f236b7-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M595,441.5 L587,429.5 603,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-759d231456b24832ad245bef11f236b7-0-3\" stroke-width=\"2px\" d=\"M770,439.5 C770,352.0 905.0,352.0 905.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-759d231456b24832ad245bef11f236b7-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M770,441.5 L762,429.5 778,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-759d231456b24832ad245bef11f236b7-0-4\" stroke-width=\"2px\" d=\"M945,439.5 C945,352.0 1080.0,352.0 1080.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-759d231456b24832ad245bef11f236b7-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M945,441.5 L937,429.5 953,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-759d231456b24832ad245bef11f236b7-0-5\" stroke-width=\"2px\" d=\"M420,439.5 C420,89.5 1095.0,89.5 1095.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-759d231456b24832ad245bef11f236b7-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1095.0,441.5 L1103.0,429.5 1087.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-759d231456b24832ad245bef11f236b7-0-6\" stroke-width=\"2px\" d=\"M420,439.5 C420,2.0 1275.0,2.0 1275.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-759d231456b24832ad245bef11f236b7-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1275.0,441.5 L1283.0,429.5 1267.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-759d231456b24832ad245bef11f236b7-0-7\" stroke-width=\"2px\" d=\"M1470,439.5 C1470,264.5 1785.0,264.5 1785.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-759d231456b24832ad245bef11f236b7-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">quantmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1470,441.5 L1462,429.5 1478,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-759d231456b24832ad245bef11f236b7-0-8\" stroke-width=\"2px\" d=\"M1645,439.5 C1645,352.0 1780.0,352.0 1780.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-759d231456b24832ad245bef11f236b7-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1645,441.5 L1637,429.5 1653,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-759d231456b24832ad245bef11f236b7-0-9\" stroke-width=\"2px\" d=\"M1295,439.5 C1295,177.0 1790.0,177.0 1790.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-759d231456b24832ad245bef11f236b7-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1790.0,441.5 L1798.0,429.5 1782.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(u'Over the last quarter Apple sold nearly 20 thousand iPods for a profit of $6 million.')\n",
        "displacy.render(doc, style='ent', jupyter=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "QZJh32HGlarh",
        "outputId": "ac7b2e90-8849-49d7-ebb5-3856140ea782"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Over \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    the last quarter\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Apple\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " sold \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    nearly 20 thousand\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    iPods\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
              "</mark>\n",
              " for a profit of \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    $6 million\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
              "</mark>\n",
              ".</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prefix"
      ],
      "metadata": {
        "id": "mXKqNnkAuGki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I like bananabread breadbanana\"\n",
        "print([t.text for t in nlp(text)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAsNhhP9nAj-",
        "outputId": "0486e4e2-7a81-4d02-e558-4a5125953599"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'like', 'banana', 'bread', 'breadbanana']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prefixes=(\"banana\",)+nlp.Defaults.prefixes"
      ],
      "metadata": {
        "id": "jXEv9AqFnMyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prefix_regex = spacy.util.compile_prefix_regex(prefixes)\n",
        "#prefixes reg exp is added to the original one"
      ],
      "metadata": {
        "id": "Ad9vL3QTniaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prefix_regex = spacy.util.compile_prefix_regex"
      ],
      "metadata": {
        "id": "UIHEptyjo-FK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.tokenizer.prefix_search = prefix_regex.search"
      ],
      "metadata": {
        "id": "UuPn4jhYnyyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print([t.text for t in nlp(text)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d6FZjpIn6fZ",
        "outputId": "0684011f-eab1-4ab6-aca2-e6e679ea7c16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'like', 'banana', 'bread', 'breadbanana']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suffix"
      ],
      "metadata": {
        "id": "ew7q7SxPuEiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I like breadbanana\"\n",
        "#print([t.text for t in nlp(text)])\n",
        "suffixes=(\"banana\",)+nlp.Defaults.suffixes\n",
        "suffix_regex = spacy.util.compile_suffix_regex(suffixes)\n",
        "nlp.tokenizer.suffix_search = suffix_regex.search\n",
        "print([t.text for t in nlp(text)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nh1PIxlEqW_-",
        "outputId": "9474f1fd-c8cb-449c-cd52-3b7e0ac0d65c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'like', 'bread', 'banana']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Infix"
      ],
      "metadata": {
        "id": "d7OZXNuMuDEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I like breadbananabread\"\n",
        "print([t.text for t in nlp(text)])\n",
        "\n",
        "infixes=(\"banana\",)+nlp.Defaults.infixes\n",
        "infix_regex = spacy.util.compile_infix_regex(infixes)\n",
        "nlp.tokenizer.infix_finditer = infix_regex.finditer\n",
        "\n",
        "print([t.text for t in nlp(text)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luLmHhiap31_",
        "outputId": "fd83b726-76bc-45ad-fa83-c091ab200c16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'like', 'breadbananabread']\n",
            "['I', 'like', 'bread', 'banana', 'bread']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deleting "
      ],
      "metadata": {
        "id": "cvE6yH7Ut-F0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"hello-[ world ] $. :)\")\n",
        "print([t.text for t in doc])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUCFiGv2s7GK",
        "outputId": "057cdbcd-1d21-4cf4-ecf9-b2f983f7655c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hello-', '[', 'world', ']', '$', '.', ':)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "suffixes = list(nlp.Defaults.suffixes)\n",
        "suffixes.remove(\"\\\\[\")\n",
        "suffix_regex = spacy.util.compile_suffix_regex(suffixes)\n",
        "nlp.tokenizer.suffix_search = suffix_regex.search"
      ],
      "metadata": {
        "id": "gbJZq2iitReL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"hello-[ world ] $. :)\")\n",
        "print([t.text for t in doc])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Axl6bXQetrXu",
        "outputId": "7c509970-87a6-42d3-8fdb-506646e2096e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hello-[', 'world', ']', '$', '.', ':)']\n"
          ]
        }
      ]
    }
  ]
}