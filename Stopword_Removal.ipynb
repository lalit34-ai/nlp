{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stopword_Removal.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1eqJ3_DT1Y5",
        "outputId": "a22e7225-49bd-4efc-b48f-83ad956442e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejnTZJJmSrrR"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Spread love everywhere you go. Let no one ever come to you without leaving happier\"\n",
        "en_stopwords = stopwords.words('english')\n",
        "lst=[]\n",
        "for token in text.split():\n",
        "  if token.lower() not in en_stopwords:\n",
        "    lst.append(token)\n",
        "print(' '.join(lst))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dau-1ZyYTOKO",
        "outputId": "14f3236a-213e-4f2a-dd88-9ae7df4553e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spread love everywhere go. Let one ever come without leaving happier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Life is what happens when you're busy making other plans\"\n",
        "en_stopwords = stopwords.words('english')\n",
        "lst=[]\n",
        "for token in text.split():\n",
        "  if token.lower() not in en_stopwords:\n",
        "    lst.append(token)\n",
        "print(' '.join(lst))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgldJDFvUBlv",
        "outputId": "b8b02dfa-5377-4835-810e-d99a8a8e5dc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Life happens busy making plans\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding words to stopwords"
      ],
      "metadata": {
        "id": "QSIL5rW4UbeS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "en_stopwords = stopwords.words('english')\n",
        "print(len(en_stopwords))\n",
        "new_stopwords = [\"you're\",\"i'll\",\"we'll\"]\n",
        "en_stopwords.extend(new_stopwords)\n",
        "len(en_stopwords\n",
        "    \n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nb9pZK6EUMnd",
        "outputId": "05c3a6f4-aa90-4662-fc5c-68d152a9b65a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "179\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "182"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Taking text from text file adn removing stopwords"
      ],
      "metadata": {
        "id": "E8Ps4XQ0cMPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "en_stopwords = stopwords.words('english')\n",
        "with open(\"text_file.txt\") as f:\n",
        "  text=f.read()\n",
        "lst=[]\n",
        "for token in text.split():\n",
        "  if token.lower() not in en_stopwords:\n",
        "    lst.append(token)\n",
        "print('Original text')\n",
        "print(text,'\\n\\n')"
      ],
      "metadata": {
        "id": "H1KqOcCDbcn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEwEGl1qcrgh",
        "outputId": "be7e4e57-c162-4db7-c5e5-39a9891555b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "text = \"nick likes to play football, however he is not too fond of tennis\"\n",
        "text_tokens = word_tokenize(text)\n",
        "tokens_stop_rem = [word for word in text_tokens if not word in stopwords.words()]\n",
        "tokens_stop_rem"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEFLPEjcbcpF",
        "outputId": "98a0b74e-c1bf-4262-b64b-9c40bff8d834"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['nick', 'likes', 'play', 'football', ',', 'however', 'fond', 'tennis']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Hai, we are here at the venue. Please hurry and reach as soon as possible!!\"\n",
        "text_tokens = word_tokenize(text)\n",
        "tokens_stop_rem = [word for word in text_tokens if not word in stopwords.words()]\n",
        "print(text)\n",
        "tokens_stop_rem"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUXMMToNbctM",
        "outputId": "bef4c3df-8db2-48d3-993b-e527f3838a5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hai, we are here at the venue. Please hurry and reach as soon as possible!!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hai',\n",
              " ',',\n",
              " 'venue',\n",
              " '.',\n",
              " 'Please',\n",
              " 'hurry',\n",
              " 'reach',\n",
              " 'soon',\n",
              " 'possible',\n",
              " '!',\n",
              " '!']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding stopwords"
      ],
      "metadata": {
        "id": "9V7DQMmXdh08"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_stopwords = stopwords.words('english')\n",
        "all_stopwords.append('play')\n",
        "text_tokens = word_tokenize(text)\n",
        "tokens_stop_rem = [word for word in text_tokens if not word in all_stopwords]\n",
        "tokens_stop_rem"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDJ6Hbwhbcuj",
        "outputId": "a02968d7-3588-4778-89f6-d330c7f9c099"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hai',\n",
              " ',',\n",
              " 'venue',\n",
              " '.',\n",
              " 'Please',\n",
              " 'hurry',\n",
              " 'reach',\n",
              " 'soon',\n",
              " 'possible',\n",
              " '!',\n",
              " '!']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sw_list = ['soon','Hai']\n",
        "all_stopwords.extend(sw_list)\n",
        "text_tokens = word_tokenize(text)\n",
        "tokens_stop_rem = [word for word in text_tokens if not word in all_stopwords]\n",
        "tokens_stop_rem"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSsoK7Hhbcx_",
        "outputId": "0f4cce3f-032b-4d43-9031-24aedd9882a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[',', 'venue', '.', 'Please', 'hurry', 'reach', 'possible', '!', '!']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove stop words"
      ],
      "metadata": {
        "id": "d7f-xr0AfTp2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_stopwords = stopwords.words('english')\n",
        "all_stopwords.remove('to')\n",
        "text_tokens = word_tokenize(text)\n",
        "tokens_stop_rem = [word for word in text_tokens if not word in all_stopwords]\n",
        "tokens_stop_rem"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cbf32hxbczX",
        "outputId": "8dbd2a74-36ab-4c30-a8ec-1ee855624323"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hai',\n",
              " ',',\n",
              " 'venue',\n",
              " '.',\n",
              " 'Please',\n",
              " 'hurry',\n",
              " 'reach',\n",
              " 'soon',\n",
              " 'possible',\n",
              " '!',\n",
              " '!']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SPACY"
      ],
      "metadata": {
        "id": "tinsyBluT-0z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "sp = spacy.load('en_core_web_sm')\n",
        "\n",
        "all_stopwords = sp.Defaults.stop_words"
      ],
      "metadata": {
        "id": "SFpooeRhfnWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"nick likes to play football, however he is not too fond of tennis\"\n",
        "text_tokens = word_tokenize(text)\n",
        "tokens_stop_rem = [word for word in text_tokens if not word in all_stopwords]\n",
        "tokens_stop_rem"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gINp-1T6f5AB",
        "outputId": "ca9e6a2f-7df2-4d78-f06d-36873cd145e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['nick', 'likes', 'play', 'football', ',', 'fond', 'tennis']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(all_stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBGqHy55gF29",
        "outputId": "100b01aa-6c5b-4292-b1c4-f23dd1bcbc70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "326"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add single stop word"
      ],
      "metadata": {
        "id": "3sKFaXxZhJ97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_stopwords = sp.Defaults.stop_words\n",
        "all_stopwords.add(\"tennis\")\n",
        "text_tokens = word_tokenize(text)\n",
        "tokens_stop_rem = [word for word in text_tokens if not word in all_stopwords]\n",
        "tokens_stop_rem"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvVJQ9H3gdXJ",
        "outputId": "e75f85bd-5c54-4aad-a057-ca63d93aa0b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['nick', 'likes', 'play', 'football', ',', 'fond']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add multiple stopwords "
      ],
      "metadata": {
        "id": "uaTqA43zhGQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_stopwords = sp.Defaults.stop_words\n",
        "all_stopwords |={\"tennis\",\"likes\"}\n",
        "text_tokens = word_tokenize(text)\n",
        "tokens_stop_rem = [word for word in text_tokens if not word in all_stopwords]\n",
        "tokens_stop_rem"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoIUuWTdgsEX",
        "outputId": "35f7e368-209d-4d9d-c8c2-c7cfce1c9b5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['nick', 'play', 'football', ',', 'fond']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove"
      ],
      "metadata": {
        "id": "FITp10RIhEB_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_stopwords = sp.Defaults.stop_words\n",
        "all_stopwords.remove('not')\n",
        "text_tokens = word_tokenize(text)\n",
        "tokens_stop_rem = [word for word in text_tokens if not word in all_stopwords]\n",
        "tokens_stop_rem"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zs249KQNg5DD",
        "outputId": "479476b3-bb0b-42b2-e65b-785101947ef2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['nick', 'play', 'football', ',', 'not', 'fond']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GenSim"
      ],
      "metadata": {
        "id": "g_M3mfnEjxd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.parsing.preprocessing import remove_stopwords"
      ],
      "metadata": {
        "id": "dc0e1-eUjzJ7"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Nick likes to play football, however he is not fond of tennis\""
      ],
      "metadata": {
        "id": "pMugKoNsj4cD"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_sentence = remove_stopwords(text)\n",
        "filtered_sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fk-adbLbkApP",
        "outputId": "62897b6a-a9dc-4b01-b0a1-f141cad9986a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Nick likes play football, fond tennis'"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "all_stopwords=gensim.parsing.preprocessing.STOPWORDS"
      ],
      "metadata": {
        "id": "T939osXZkNmb"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(all_stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAea7_GtkNob",
        "outputId": "f15845bf-89ad-4520-aa62-65c15a0d46dc"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "337"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add stopwords"
      ],
      "metadata": {
        "id": "TO8DrrROmifT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "all_stopwords_gensim = STOPWORDS.union(set(['likes','play']))\n",
        "text_tokens = word_tokenize(text)\n",
        "tokens_without_sw = [word for word in text_tokens if not word in all_stopwords_gensim]"
      ],
      "metadata": {
        "id": "hTUVKU5mkNrV"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_without_sw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nrx5luWgkNsZ",
        "outputId": "ad6c63cd-e1c5-4490-81d3-45bcac46db9a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Nick', 'football', ',', 'fond', 'tennis']"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove stopwords"
      ],
      "metadata": {
        "id": "RsbvZ9kLmft8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_stopwords=gensim.parsing.preprocessing.STOPWORDS\n",
        "sw_list={\"not\"}\n",
        "all_stopwords=STOPWORDS.difference(sw_list)\n",
        "text_tokens = word_tokenize(text)\n",
        "tokens_without_sw = [word for word in text_tokens if not word in all_stopwords]\n",
        "tokens_without_sw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J__ecDW9kNxI",
        "outputId": "9fa718b6-17b6-4a8c-bfc7-8a7217d3e098"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Nick', 'likes', 'play', 'football', ',', 'not', 'fond', 'tennis']"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    }
  ]
}