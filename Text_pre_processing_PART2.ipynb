{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_Pre-processing_PART2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Removing URL"
      ],
      "metadata": {
        "id": "0Nzm8sQ5mnlq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_ewVODPjfNT"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_urls(text):\n",
        "  url_pattern = r'http?://\\S+ | www\\. \\S+'\n",
        "  without_url = re.sub(pattern=url_pattern, repl=' ',string = text)\n",
        "  return without_url\n",
        "ex_url=\"\"\" this is an example of http://google.com\"\"\"\n",
        "\n",
        "url_result = remove_urls(ex_url)\n",
        "print(url_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QSHPr1TjhOV",
        "outputId": "63466164-f950-4a4b-b583-ea7454b40b6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " this is an example of http://google.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert num to text"
      ],
      "metadata": {
        "id": "MbNQ4BXDk2qw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install num2words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--Ygnkacl42l",
        "outputId": "90fbb6ff-a3ef-449c-d3a0-0c900c733efc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: num2words in /usr/local/lib/python3.7/dist-packages (0.5.10)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.7/dist-packages (from num2words) (0.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from num2words import num2words\n",
        "\n",
        "def num_to_word(text):\n",
        "  after_split = text.split()\n",
        "  for idx in range(len(after_split)):\n",
        "    if after_split[idx].isdigit():\n",
        "      after_split[idx] = num2words(after_split[idx])\n",
        "  nums_to_words = ' '.join(after_split)\n",
        "  return nums_to_words\n",
        "print(\"Input: this is an example of 1 to one, 2 to two\")\n",
        "ex_nums = \"this is an example of 1 to one, 2 to two\"\n",
        "print(\"Output:\",num_to_word(ex_nums))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNjXNts5k4-w",
        "outputId": "ebcd35f6-2336-48bf-abf9-ad10beb65cd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: this is an example of 1 to one, 2 to two\n",
            "Output: this is an example of one to one, two to two\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ex_nums = \"28\"\n",
        "print(\"Output:\",num_to_word(ex_nums))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQknmf3mlwa8",
        "outputId": "728f2ed6-968f-4fb5-c7c8-ea4e2fd6554a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output: twenty-eight\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4BmAfTETsVre"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spell checker"
      ],
      "metadata": {
        "id": "QXG_mjWrmyHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# library used for correcting spellings\n",
        "\n",
        "!pip install pyspellchecker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NK8I4C2wm3Hv",
        "outputId": "3eaf2994-922d-497a-8953-421a4bf74eef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspellchecker\n",
            "  Downloading pyspellchecker-0.6.3-py3-none-any.whl (2.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7 MB 5.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: pyspellchecker\n",
            "Successfully installed pyspellchecker-0.6.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spellchecker import SpellChecker\n",
        "spell_corre = SpellChecker()\n",
        "def spell_correction(text):\n",
        "  correct_words=[]\n",
        "  miss_words = spell_corre.unknown(text.split())\n",
        "  for each_word in text.split():\n",
        "    if each_word in miss_words:\n",
        "      right_word = spell_corre.correction(each_word)\n",
        "      correct_words.append(right_word)\n",
        "    else:\n",
        "      correct_words.append(each_word)\n",
        "  correct_spelling = ' '.join(correct_words)\n",
        "  return correct_spelling"
      ],
      "metadata": {
        "id": "7Gj5I3jsnIjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ex_misspell = 'this is an axample of corectin'\n",
        "correct_result = spell_correction(ex_misspell)\n",
        "correct_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ZjXPPfOsoUde",
        "outputId": "12572b9c-8fda-408a-c378-35203fa5de89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'this is an example of correcting'"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ex_misspell = 'Dogs and cats are frinds'\n",
        "correct_result = spell_correction(ex_misspell)\n",
        "correct_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "PMaedYZqpVMN",
        "outputId": "673cb208-a884-43d2-a16a-304f043d5686"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Dogs and cats are friends'"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install autocorrect"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hpWBS9zuMzp",
        "outputId": "d351a955-a952-41da-8d25-070ea8a0d56c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autocorrect\n",
            "  Downloading autocorrect-2.6.1.tar.gz (622 kB)\n",
            "\u001b[?25l\r\u001b[K     |▌                               | 10 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |█                               | 20 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 30 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |██                              | 40 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 51 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 61 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 81 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 92 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 102 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 112 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 122 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 133 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 143 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████                        | 153 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 163 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 174 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 184 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 194 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 204 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 215 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 225 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 235 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 245 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 256 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 266 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 276 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 286 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 296 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 307 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 317 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 327 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 337 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 348 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 358 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 368 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 378 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 389 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 399 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 409 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 419 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 430 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 440 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 450 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 460 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 471 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 481 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 491 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 501 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 512 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 522 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 532 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 542 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 552 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 563 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 573 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 583 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 593 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 604 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 614 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 622 kB 5.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: autocorrect\n",
            "  Building wheel for autocorrect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autocorrect: filename=autocorrect-2.6.1-py3-none-any.whl size=622382 sha256=b21e83d5e930093216b3f85e727313eec487791faf3d6f1403a6ff8c525bb6c5\n",
            "  Stored in directory: /root/.cache/pip/wheels/54/d4/37/8244101ad50b0f7d9bffd93ce58ed7991ee1753b290923934b\n",
            "Successfully built autocorrect\n",
            "Installing collected packages: autocorrect\n",
            "Successfully installed autocorrect-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGBvr8xPuVk5",
        "outputId": "0583ebe3-d91e-497f-b05b-63203074d2b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from autocorrect import Speller\n",
        "from nltk import word_tokenize\n",
        "\n",
        "def spell_autocorrection(text):\n",
        "  correct_spell_words=[]\n",
        "  spell_corrector = Speller(lang = 'en')\n",
        "  for word in word_tokenize(text):\n",
        "    correct_word = spell_corrector(word)\n",
        "    correct_spell_words.append(correct_word)\n",
        "  correct_spelling = ' '.join(correct_spell_words)\n",
        "  return correct_spelling\n",
        "\n",
        "ex_misspell = 'Dogs and cats are frinds'\n",
        "correct_result = spell_autocorrection(ex_misspell)\n",
        "correct_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "1Vlyz7C1plnR",
        "outputId": "f0ba69df-e5e9-471b-e6b9-af3ef6782390"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Dogs and cats are friends'"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ASCII"
      ],
      "metadata": {
        "id": "x7IpP32atdwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unidecode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EKV_7Hkt4mL",
        "outputId": "70e40778-4327-43b1-9aec-8c3a8af65ead"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.2-py3-none-any.whl (235 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 26.0 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 20 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 40 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |███████                         | 51 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 61 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 81 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 92 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 133 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 143 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 153 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 163 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 174 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 184 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 194 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 204 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 215 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 225 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 235 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 235 kB 5.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import unidecode\n",
        "def accented_toascii(text):\n",
        "  text= unidecode.unidecode(text)\n",
        "  return text\n",
        "ex_accented = \"\"\"This is an example text with accented characters like deep learning and computer vision etc.\"\"\"\n",
        "print(accented_toascii(ex_accented))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XI9Ddxeftcz4",
        "outputId": "613e689b-cb95-4255-9d03-356c1b45d791"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is an example text with accented characters like deep learning and computer vision etc.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*learn*   \n",
        "minimum edit distance algorithm   \n"
      ],
      "metadata": {
        "id": "3ftL1c4jua7k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "py_file_location = \"/content/drive/MyDrive/NLP/\"\n",
        "sys.path.append(os.path.abspath(py_file_location))\n"
      ],
      "metadata": {
        "id": "tI11stdsuk3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from contraction import CONTRACTION_MAP"
      ],
      "metadata": {
        "id": "WDIej07Pv1N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def expand_contractions(contraction):\n",
        "  match = contraction.group(0)\n",
        "  # first char from matching contraction (D for Doesn't)\n",
        "  first_char = match[0]\n",
        "  if contraction_mapping.get(match):\n",
        "    expanded_contraction = contraction_mapping.get(match)\n",
        "  else:\n",
        "    expanded_contraction = contraction_mapping.get(match.lower())\n",
        "    expanded_contraction = first_char+expanded_contraction[1:]\n",
        "  return expanded_contraction\n",
        "# expending contractions\n",
        "contraction_mapping = CONTRACTION_MAP\n",
        "# take all key values from contraction_mapping\n",
        "contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())),\n",
        "flags=re.IGNORECASE|re.DOTALL)\n",
        "# example text with contractions\n",
        "ex_contractions = \"\"\"\n",
        "Sometimes our mind doesn't work properly.\n",
        "\"\"\"\n",
        "# substitute result of function in the text\n",
        "expanded_text = contractions_pattern.sub(expand_contractions, ex_contractions)\n",
        "# replacing apostrophe with empty string (to remove apostrophe)\n",
        "expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
        "print(f\"Result :- \\n{expanded_text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftUvYw7fwTBn",
        "outputId": "b360e951-dca2-443f-8145-44ba052f2d91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result :- \n",
            "\n",
            "Sometimes our mind does not work properly.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting Emojis to words"
      ],
      "metadata": {
        "id": "fMO-G3a4vBiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "import re\n",
        "py_file_location = \"/content/drive/MyDrive/NLP/\"\n",
        "sys.path.append(os.path.abspath(py_file_location))"
      ],
      "metadata": {
        "id": "ndCOzTyQuk6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from emoticons_list import EMO_UNICODE\n",
        "def emoji_words(text):\n",
        "  for emot in UNICODE_EMO:\n",
        "    emoji_pattern = r'('+emot+')'\n",
        "    # replace\n",
        "    emoji_words = UNICODE_EMO[emot]\n",
        "    replace_text = emoji_words.replace(\",\",\"\")\n",
        "    replace_text = replace_text.replace(\":\",\"\")\n",
        "    replace_text_list = replace_text.split()\n",
        "    emoji_name = '_'.join(replace_text_list)\n",
        "    text = re.sub(emoji_pattern, emoji_name, text)\n",
        "  return text\n",
        "# convert emo_unicode to unicode_emo\n",
        "UNICODE_EMO = {v: k for k, v in EMO_UNICODE.items()}\n",
        "# example text for converting emojis to words\n",
        "ex_emoji = \"\"\"\n",
        "This is a test 😻 👍🏿\n",
        "\"\"\"\n",
        "emoji_result = emoji_words(ex_emoji)\n",
        "print(f\"Result after converting emojis to corresponding words :- \\n{emoji_result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-X0e1lkGwDlO",
        "outputId": "988c9193-217c-4a1f-dd22-c2ea0b749700"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result after converting emojis to corresponding words :- \n",
            "\n",
            "This is a test smiling_cat_face_with_heart-eyes thumbs_updark_skin_tone\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting enoticons to text"
      ],
      "metadata": {
        "id": "urzd_hLTxD8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from emoticons_list import EMOTICONS\n",
        "def emoticons_words(text):\n",
        "  for emot in EMOTICONS:\n",
        "    emoticon_pattern = r'('+emot+')'\n",
        "      # replace\n",
        "    emoticon_words = EMOTICONS[emot]\n",
        "    replace_text = emoticon_words.replace(\",\",\"\")\n",
        "    replace_text = replace_text.replace(\":\",\"\")\n",
        "    replace_text_list = replace_text.split()\n",
        "    emoticon_name = '_'.join(replace_text_list)\n",
        "    text = re.sub(emoticon_pattern, emoticon_name, text)\n",
        "  return text\n",
        "# example sentence for converting emoticons to words\n",
        "ex_emoticons = \"\"\"\n",
        "Hello this is a sentence with these 2 emoticons :-( & :-)\n",
        "\"\"\"\n",
        "emoticons_result = emoticons_words(ex_emoticons)\n",
        "print(f\"After converting emoticons to words :- \\n{emoticons_result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0KQuTOCxGwD",
        "outputId": "1cd31e58-a5af-460c-cf79-893140d97b6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After converting emoticons to words :- \n",
            "\n",
            "Hello this is a sentence with these 2 emoticons Frown_sad_andry_or_pouting & Happy_face_smiley\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove single characters and extra spaces"
      ],
      "metadata": {
        "id": "nluQa2fCyT9V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#single char removal\n",
        "pattern = r'\\s[a-zA-Z]\\s'\n",
        "text = \"Hello      All! Welcome a  Home   !!!\"\n",
        "re.sub(pattern=r'\\s[a-zA-Z]\\s', repl=\" \",string=text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "xKyn3ersx5c-",
        "outputId": "db45a643-a2da-4b3b-eab7-ecd3450d0b5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Hello      All! Welcome  Home   !!!'"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ]
}